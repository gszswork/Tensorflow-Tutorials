# -*- coding: utf-8 -*-
"""CNN_CIFAR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SnzI8nq3c6jJ-5ieMUsflj7UfeVGFsya
"""

# key word: CNN, Keras, CIFAR-10, Image classification

# Dataset: The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 
# classes, with 6000 images per class. There are 50000 training images and 
# 10000 test images. The classes are mutually exclusive and there is no overlap 
# between them.

"""Dataset link: [CIFAR-10 Dataset](https://www.cs.toronto.edu/%7Ekriz/cifar.html)"""

# pre-loading
import tensorflow as tf

from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt

# data-loading
(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()

# Normalize pixel values, the pixel values are between 0-255 (8-bits color)
train_images = train_images / 255.0
test_images = test_images / 255.0

# plot the data
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']
plt.figure(figsize=(10,10))
for i in range(25):
  plt.subplot(5,5,i+1)
  plt.imshow(train_images[i], cmap=plt.cm.binary)
  plt.xlabel(class_names[train_labels[i][0]])
plt.show()

# model construct 
# CNN 忽略batch size把 (height, width, channels)格式的数据作为输入
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D(2, 2))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D(2, 2))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.summary()

model.add(layers.Flatten())
model.add(layers.Dense(64, activation = 'relu'))
model.add(layers.Dense(10))
model.summary()

model.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=['accuracy']
)
history = model.fit(train_images, train_labels, epochs=10, 
                    validation_data = (test_images, test_labels))

"""CNN的训练时间的确是慢很多，也因此在2012年之前因为计算机性能的限制一直未能发展和应用。"""

plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()